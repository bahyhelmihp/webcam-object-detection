{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d136f68-3302-4d85-aa29-489621fe3ac6",
   "metadata": {},
   "source": [
    "### Webcam Object Detection using Tensorflow 2\n",
    "##### Bahy Helmi Hartoyo Putra - bahyhelmi97@gmail.com\n",
    "- Based on the [Webcam Object Detection - TF Example]('https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/object_detection_camera.html#sphx-glr-auto-examples-object-detection-camera-py'), with a slight modification.\n",
    "- Using Tensorflow 2 Object Detection API to classify the object on the input video.\n",
    "- Using pre-recorded webcam video as an input and extract the result video with bounding boxes attached. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d222a-0f81-4e76-8d7f-72a33e717767",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87db8244-62e9-48c4-a96d-5ea63343fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbac9bc-20ee-48ad-817f-1c4b33dff3b6",
   "metadata": {},
   "source": [
    "#### Create Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c116ddb9-15fe-4c98-a408-cd8b7645b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data/models directory\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
    "for dir in [DATA_DIR, MODELS_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0159e-04e1-4095-af76-51996231cc45",
   "metadata": {},
   "source": [
    "#### Download & Extract Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd161e1c-51a1-4b2a-b0d0-3be4b709fc4a",
   "metadata": {},
   "source": [
    "- The particular detection algorithm that are being used in this session is the **SSD ResNet101 V1 FPN 640x640**.\n",
    "- These processes of downloading & extracting can always be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b545a3e-beeb-47a9-a28e-eb96fec71c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract model\n",
    "MODEL_DATE = '20200711'\n",
    "MODEL_NAME = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'\n",
    "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
    "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
    "\n",
    "\n",
    "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
    "\n",
    "if not os.path.exists(PATH_TO_CKPT):\n",
    "    print('Downloading model. This may take a while... ', end='')\n",
    "    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
    "    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
    "    tar_file.extractall(MODELS_DIR)\n",
    "    tar_file.close()\n",
    "    \n",
    "    os.remove(PATH_TO_MODEL_TAR)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0614e407-a861-4e40-98a5-a62693d4c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download labels file\n",
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "LABELS_DOWNLOAD_BASE = \\\n",
    "    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\n",
    "\n",
    "if not os.path.exists(PATH_TO_LABELS):\n",
    "    print('Downloading label file... ', end='')\n",
    "    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72dcd87-f181-45d1-8abb-11980b9bc3f5",
   "metadata": {},
   "source": [
    "#### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d00a811-d1f0-4b43-b93c-762653c6943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU(s) available.\n"
     ]
    }
   ],
   "source": [
    "# Enable GPU dynamic memory allocation\n",
    "# Currently this laptop does not have any GPU, so it won't affect anything\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if len(gpus) == 0:\n",
    "    print(\"No GPU(s) available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc9a508-7525-4d08-a33f-0040b15810b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9666f5-34d0-4b13-9616-5454da18bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored.\n"
     ]
    }
   ],
   "source": [
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "print(\"Checkpoint restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35909c37-4930-4d6a-94d8-e57ae25e8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae7941f3-0ab5-4784-9f36-1a255b55357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d5edde-814b-4e83-85af-3dfcec32a3db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'person'},\n",
       " 2: {'id': 2, 'name': 'bicycle'},\n",
       " 3: {'id': 3, 'name': 'car'},\n",
       " 4: {'id': 4, 'name': 'motorcycle'},\n",
       " 5: {'id': 5, 'name': 'airplane'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the first 5 labels\n",
    "dict(list(category_index.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e3b22-d79c-4ce5-bf22-81964dab4121",
   "metadata": {},
   "source": [
    "#### Load the Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "136bedd7-9f1d-475a-b0b1-40984923d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0) # Disabled since currently native webcam does not supported on WSL\n",
    "cap = cv2.VideoCapture('data/videos/webcam.mp4') # Using pre-recorded webcam video\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7be776f-eb64-4bbd-aa2b-8b62c135caf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of frames and FPS on my input video\n",
    "n_frames, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e055286-b122-483a-8463-eb30caa9b744",
   "metadata": {},
   "source": [
    "#### Predict Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa8aaa-3fd6-460d-9d1a-07a5fc9b8840",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing videos.."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 19/507 [01:04<09:19,  1.15s/it] "
     ]
    }
   ],
   "source": [
    "print(\"Processing videos..\", end=\"\")\n",
    "for i in tqdm(range(n_frames-1)):\n",
    "    # Read frame from camera\n",
    "    ret, image_np = cap.read()\n",
    "\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    # Converting image frame into tensor\n",
    "    input_tensor = tf.convert_to_tensor(image_np_expanded, dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    # Putting bounding box and label on frame\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'][0].numpy(),\n",
    "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "          detections['detection_scores'][0].numpy(),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    # Display output\n",
    "    image_np_with_detections = cv2.resize(image_np_with_detections, (800, 600))\n",
    "    cv2.imwrite(\"data/frames/%s.jpg\" % i, image_np_with_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b838c35-a7c2-45ef-9135-c756539f4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the video\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb3164-a02c-4d09-9bb1-fe20cef1559b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample one result frame (sanity check)\n",
    "sample_img = cv2.imread(\"data/frames/21.jpg\")\n",
    "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021792b9-b3d0-402e-894f-33571ec76a75",
   "metadata": {},
   "source": [
    "#### Convert Frames into Result Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee1eca-d49f-41cb-99c8-d2273fc39c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load frames\n",
    "frames = [cv2.imread(\"data/frames/%s.jpg\" % i) for i in tqdm(range(n_frames-1))]\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b490af-e97d-4e21-99cf-87ee9773bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write frames into video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('data/videos/result_webcam.avi', fourcc, fps, (800,600))\n",
    "\n",
    "for frame in tqdm(frames):\n",
    "    out.write(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
